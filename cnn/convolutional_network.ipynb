{
 "metadata": {
  "name": "",
  "signature": "sha256:d62260692a086f750408ba9182ada7bb92292279c611b4b106ee93bb8a9a5a6e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# pylearn2 tutorial: Convolutional network\n",
      "by [Ian Goodfellow](http://www-etud.iro.umontreal.ca/~goodfeli)\n",
      "\n",
      "## Introduction\n",
      "This ipython notebook will teach you the basics of how convolutional networks work, and show you how to use multilayer perceptrons in pylearn2.\n",
      "\n",
      "To do this, we will go over several concepts:\n",
      "\n",
      "Part 1: What pylearn2 is doing for you in this example\n",
      "\n",
      "   - Review of multilayer perceptrons, and how convolutional networks are similar\n",
      "\n",
      "   - Convolution and the equivariance property\n",
      "\n",
      "   - Pooling and the invariance property\n",
      "\n",
      "   - A note on using convolution in research papers\n",
      "\n",
      "Part 2: How to use pylearn2 to train a convolutional network\n",
      "\n",
      "    - pylearn2 Spaces\n",
      "\n",
      "    - MNIST classification example\n",
      "\n",
      "\n",
      "Note that this won't explain in detail how the individual classes are implemented. The classes\n",
      "follow pretty good naming conventions and have pretty good docstrings, but if you have trouble\n",
      "understanding them, write to me and I might add a part 3 explaining how some of the parts work\n",
      "under the hood.\n",
      "\n",
      "Please write to pylearn-dev@googlegroups.com if you encounter any problem with this tutorial."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Requirements\n",
      "\n",
      "Before running this notebook, you must have installed pylearn2.\n",
      "Follow the [download and installation instructions](http://deeplearning.net/software/pylearn2/#download-and-installation)\n",
      "if you have not yet done so.\n",
      "\n",
      "This tutorial also assumes you already know about multilayer perceptrons, and know how to train and evaluate a multilayer perceptron in pylearn2. If not, work through multilayer_perceptron.ipynb before starting this tutorial.\n",
      "\n",
      "It's also strongly recommend that you run this notebook with THEANO_FLAGS=\"device=gpu\". This is a processing intensive example and the GPU will make it run a lot faster, if you have one available. Execute the next cell to verify that you are using the GPU.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import theano\n",
      "print theano.config.device"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gpu\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using gpu device 0: GeForce GTX 480\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Part 1: What pylearn2 is doing for you in this example\n",
      "\n",
      "In this part, we won't get into any specifics of pylearn2 yet. We'll just discuss what a convolutional network is. If you already know about convolutional networks, feel free to skip to part 2.\n",
      "\n",
      "\n",
      "### Review of multilayer perceptrons, and how convolutional networks are similar\n",
      "\n",
      "In multilayer_perceptron.ipynb, we saw how the multilayer perceptron (MLP) is a versatile model that can do many things. In this series of tutorials, we think of it as a classification model that learns to map an input vector $x$ to a probability distribution $p(y\\mid x)$ where $y$ is a categorical value with $k$ different values. Using a dataset $\\mathcal{D}$ of $(x, y)$, we can train any such probabilistic model by maximizing the log likelihood,\n",
      "\n",
      "$$ \\sum_{x,y \\in \\mathcal{D} } \\log P(y \\mid x). $$\n",
      "\n",
      "The multilayer perceptron defines $P(y \\mid x)$ to be the composition of several simpler functions. Each function being composed can be thought of as another \"layer\" or \"stage\" of processing.\n",
      "\n",
      "A convolutional network is nothing but a multilayer perceptron where some layers take a very special form, which we will call \"convolutional layers\". These layers are specially designed for processing inputs where the indices of the elements have some topological significance.\n",
      "\n",
      "For example, if we represent a grayscale image as an array $I$ with the array indices corresponding to physical locations in the image, then we know that the element $I_{i,j}$ represents something that is spatially close to the element $I_{i+1,j}$. This is in contrast to a vector representation of an image. If $I$ is a vector, then $I_i$ might not be very close at all to $I_{i+1}$, depending on whether the image was converted to vector form in row-major or column major format and depending on whether $i$ is close to the end of a row or column.\n",
      "\n",
      "Other kinds of data with topological in the indices include time series data, where some series $S$ can be indexed by a time variable $t$. We know that $S_t$ and $S_{t+1}$ come from close together in time. We can also think of the (row, column, time) indices of video data as providing topological information.\n",
      "\n",
      "Suppose $T$ is a function that can translate (move) an input in the space defined by its indices by some amount $x$.\n",
      "In other words,\n",
      "$T(S,x)_i = S_j$ where $j=i-x$ (a MathJax or ipython bug seems to prevent me from putting $i-x$ in a subscript).\n",
      "Convolutional layers are an example of a function $f$ designed with the property $f(T(S,x)) \\approx f(S)$ for small x.\n",
      "\n",
      "This means if a neural network can recognize a handwritten digit in one position, it can recognize it when it is slightly shifted to a nearby position. Being able to recognize shifted versions of previously seen inputs greatly improves the generalization performance of convolutional networks.\n",
      "\n",
      "\n",
      "## Convolution and the equivariance property\n",
      "\n",
      "TODO\n",
      "\n",
      "## Pooling and the invariance property\n",
      "\n",
      "TODO\n",
      "\n",
      "## A note on using convolution in research papers\n",
      "\n",
      "TODO"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Part 2: How to use pylearn2 to train an MLP\n",
      "\n",
      "Now that we've described the theory of what we're going to do, it's time to do it! This part describes\n",
      "how to use pylearn2 to run the algorithms described above.\n",
      "\n",
      "As in the MLP tutorial, we will use the convolutional net to do optical character recognition on the MNIST dataset.\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## pylearn2 Spaces\n",
      "\n",
      "In many places in pylearn2, we would like to be able to process several different kinds of data. In previous tutorials, we've just talked about data that could be preprocessed into a vector representation. Our algorithms all worked on vector spaces. However, it's often useful to format data in other ways. The pylearn2 Space object is used to specify the format for data. The VectorSpace class represents the typical vector formatted data we've used so far. The only thing it needs to encode about the data is its dimensionality, i.e., how many elements the vector has. In this tutorial we will start to explicitly represent images as having 2D structure, so we need to use the Conv2DSpace. The Conv2DSpace object describes how to represent a collection of images as a 4-tensor.\n",
      "\n",
      "One thing the Conv2DSpace object needs to describe is the shape of the space--how big is the image in terms of rows and columns of pixels? Also, the image may have multiple channels. In this example, we use a grayscale input image, so the input only has one channel. Color images require three channels to store the red, green, and blue pixels at each location. We can also think of the output of each convolution layer as living in a Conv2DSpace, where each kernel outputs a different channel. Finally, the Conv2DSpace specifies what each axis of the 4-tensor means. The default is for the first axis to index over different examples, the second axis to index over channels, and the last two to index over rows and columns, respectively. This is the format that theano's 2D convolution code uses, but other libraries exist that use other formats and we often need to convert between them."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## MNIST classification example"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Setting up a convolutional network in pylearn2 is essentially the same as setting up any other MLP. In the YAML experiment description below, there are really just two things to take note of.\n",
      "\n",
      "First, rather than using \"nvis\" to specify the input that the MLP will take, we use a parameter called \"input_space\". \"nvis\" is actually shorthand; if you pass an integer n to nvis, it will set input_space to VectorSpace(n). Now that we are using a convolutional network, we need the input to be formatted as a collection of images so that the convolution operator will have a 2D space to work on.\n",
      "\n",
      "Second, we make a few layers of the network be \"ConvRectifiedLinear\" layers. Putting some convolutional layers in the network makes those layers invariant to small translations, so the job of the remaining layers is much easier.\n",
      "\n",
      "We don't need to do anything special to make the Softmax layer on top work with these convolutional layers. The MLP class will tell the Softmax class that its input is now coming from a Conv2DSpace. The Softmax layer will then use the Conv2DSpace's convert method to convert the 2D output from the convolutional layer into a batch of vector-valued examples.\n",
      "\n",
      "The model and training is defined in conv.yaml file. Here we load it and set some of it's hypyer-parameters."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train = open('conv.yaml', 'r').read()\n",
      "train_params = {'train_stop': 50000,\n",
      "                    'valid_stop': 60000,\n",
      "                    'test_stop': 10000,\n",
      "                    'batch_size': 100,\n",
      "                    'output_channels_h2': 64, \n",
      "                    'output_channels_h3': 64,  \n",
      "                    'max_epochs': 500,\n",
      "                    'save_path': '.'}\n",
      "train = train % (train_params)\n",
      "print train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "!obj:pylearn2.train.Train {\n",
        "    dataset: &train !obj:pylearn2.datasets.mnist.MNIST {\n",
        "        which_set: 'train',\n",
        "        one_hot: 1,\n",
        "        start: 0,\n",
        "        stop: 50000\n",
        "    },\n",
        "    model: !obj:pylearn2.models.mlp.MLP {\n",
        "        batch_size: 100,\n",
        "        input_space: !obj:pylearn2.space.Conv2DSpace {\n",
        "            shape: [28, 28],\n",
        "            num_channels: 1\n",
        "        },\n",
        "        layers: [ !obj:pylearn2.models.mlp.ConvRectifiedLinear {\n",
        "                     layer_name: 'h2',\n",
        "                     output_channels: 64,\n",
        "                     irange: .05,\n",
        "                     kernel_shape: [5, 5],\n",
        "                     pool_shape: [4, 4],\n",
        "                     pool_stride: [2, 2],\n",
        "                     max_kernel_norm: 1.9365\n",
        "                 }, !obj:pylearn2.models.mlp.ConvRectifiedLinear {\n",
        "                     layer_name: 'h3',\n",
        "                     output_channels: 64,\n",
        "                     irange: .05,\n",
        "                     kernel_shape: [5, 5],\n",
        "                     pool_shape: [4, 4],\n",
        "                     pool_stride: [2, 2],\n",
        "                     max_kernel_norm: 1.9365\n",
        "                 }, !obj:pylearn2.models.mlp.Softmax {\n",
        "                     max_col_norm: 1.9365,\n",
        "                     layer_name: 'y',\n",
        "                     n_classes: 10,\n",
        "                     istdev: .05\n",
        "                 }\n",
        "                ],\n",
        "    },\n",
        "    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {\n",
        "        batch_size: 100,\n",
        "        learning_rate: .01,\n",
        "        learning_rule: !obj:pylearn2.training_algorithms.learning_rule.Momentum {\n",
        "            init_momentum: .5\n",
        "        },\n",
        "        monitoring_dataset:\n",
        "            {\n",
        "                'valid' : !obj:pylearn2.datasets.mnist.MNIST {\n",
        "                              which_set: 'train',\n",
        "                              one_hot: 1,\n",
        "                              start: 50000,\n",
        "                              stop:  60000\n",
        "                          },\n",
        "                'test'  : !obj:pylearn2.datasets.mnist.MNIST {\n",
        "                              which_set: 'test',\n",
        "                              one_hot: 1,\n",
        "                              stop: 10000\n",
        "                          }\n",
        "            },\n",
        "        cost: !obj:pylearn2.costs.cost.SumOfCosts { costs: [\n",
        "            !obj:pylearn2.costs.cost.MethodCost {\n",
        "                method: 'cost_from_X'\n",
        "            }, !obj:pylearn2.costs.mlp.WeightDecay {\n",
        "                coeffs: [ .00005, .00005, .00005 ]\n",
        "            }\n",
        "            ]\n",
        "        },\n",
        "        termination_criterion: !obj:pylearn2.termination_criteria.And {\n",
        "            criteria: [\n",
        "                !obj:pylearn2.termination_criteria.MonitorBased {\n",
        "                    channel_name: \"valid_y_misclass\",\n",
        "                    prop_decrease: 0.50,\n",
        "                    N: 10\n",
        "                },\n",
        "                !obj:pylearn2.termination_criteria.EpochCounter {\n",
        "                    max_epochs: 500\n",
        "                },\n",
        "            ]\n",
        "        },\n",
        "    },\n",
        "    extensions:\n",
        "        [ !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {\n",
        "             channel_name: 'valid_y_misclass',\n",
        "             save_path: \"./convolutional_network_best.pkl\"\n",
        "        }, !obj:pylearn2.training_algorithms.learning_rule.MomentumAdjustor {\n",
        "            start: 1,\n",
        "            saturate: 10,\n",
        "            final_momentum: .99\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we use pylearn2's yaml_parse.load to construct the Train object, and run its main loop. The same thing could be accomplished by running pylearn2's train.py script on a file containing the yaml string.\n",
      "\n",
      "Execute the next cell to train the model. This will take several minutes and possible as much as a few hours depending on how fast your computer is."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pylearn2.config import yaml_parse\n",
      "train = yaml_parse.load(train)\n",
      "train.main_loop()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Input shape: (28, 28)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Detector space: (24, 24)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Output space: (11, 11)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Input shape: (11, 11)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Detector space: (7, 7)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Output space: (3, 3)\n"
       ]
      },
      {
       "ename": "NoDataPathError",
       "evalue": "You need to define your PYLEARN2_DATA_PATH environment variable. If you are\nusing a computer at LISA, this should be set to /data/lisa/data.\n\nPlatform-specific instructions for setting environment variables:\n\nLinux\n=====\nOn most linux setups, you can define your environment variable by adding this\nline to your ~/.bashrc file:\n\nexport PYLEARN2_VIEWER_COMMAND=\"eog --new-instance\"\n\n*** YOU MUST INCLUDE THE WORD \"export\". DO NOT JUST ASSIGN TO THE ENVIRONMENT VARIABLE ***\nIf you do not include the word \"export\", the environment variable will be set\nin your bash shell, but will not be visible to processes that you launch from\nit, like the python interpreter.\n\nDon't forget that changes from your .bashrc file won't apply until you run\n\nsource ~/.bashrc\n\nor open a new terminal window. If you're seeing this from an ipython notebook\nyou'll need to restart the ipython notebook, or maybe modify os.environ from\nan ipython cell.\n\nMac OS X\n========\n\nEnvironment variables on Mac OS X work the same as in Linux, except you should\nmodify and run the \"source\" command on ~/.profile rather than ~/.bashrc.\n\n\nOriginal exception:\n\tKeyError: PYLEARN2_DATA_PATH",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNoDataPathError\u001b[0m                           Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-5-a29d25125a51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpylearn2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0myaml_parse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myaml_parse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/perellm1/git/pylearn2/pylearn2/config/yaml_parse.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(stream, environ, instantiate, **kwargs)\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[0mproxy_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minstantiate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_instantiate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproxy_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mproxy_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/perellm1/git/pylearn2/pylearn2/config/yaml_parse.py\u001b[0m in \u001b[0;36m_instantiate\u001b[1;34m(proxy, bindings)\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[0mbindings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mProxy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_instantiate_proxy_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbindings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[1;31m# Recurse on the keys too, for backward compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/perellm1/git/pylearn2/pylearn2/config/yaml_parse.py\u001b[0m in \u001b[0;36m_instantiate_proxy_tuple\u001b[1;34m(proxy, bindings)\u001b[0m\n\u001b[0;32m    227\u001b[0m                                           'supported in proxy instantiation')\n\u001b[0;32m    228\u001b[0m             kwargs = dict((k, _instantiate(v, bindings))\n\u001b[1;32m--> 229\u001b[1;33m                           for k, v in proxy.keywords.iteritems())\n\u001b[0m\u001b[0;32m    230\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchecked_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/perellm1/git/pylearn2/pylearn2/config/yaml_parse.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m((k, v))\u001b[0m\n\u001b[0;32m    227\u001b[0m                                           'supported in proxy instantiation')\n\u001b[0;32m    228\u001b[0m             kwargs = dict((k, _instantiate(v, bindings))\n\u001b[1;32m--> 229\u001b[1;33m                           for k, v in proxy.keywords.iteritems())\n\u001b[0m\u001b[0;32m    230\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchecked_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/perellm1/git/pylearn2/pylearn2/config/yaml_parse.py\u001b[0m in \u001b[0;36m_instantiate\u001b[1;34m(proxy, bindings)\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[0mbindings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mProxy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_instantiate_proxy_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbindings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[1;31m# Recurse on the keys too, for backward compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/perellm1/git/pylearn2/pylearn2/config/yaml_parse.py\u001b[0m in \u001b[0;36m_instantiate_proxy_tuple\u001b[1;34m(proxy, bindings)\u001b[0m\n\u001b[0;32m    227\u001b[0m                                           'supported in proxy instantiation')\n\u001b[0;32m    228\u001b[0m             kwargs = dict((k, _instantiate(v, bindings))\n\u001b[1;32m--> 229\u001b[1;33m                           for k, v in proxy.keywords.iteritems())\n\u001b[0m\u001b[0;32m    230\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchecked_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/perellm1/git/pylearn2/pylearn2/config/yaml_parse.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m((k, v))\u001b[0m\n\u001b[0;32m    227\u001b[0m                                           'supported in proxy instantiation')\n\u001b[0;32m    228\u001b[0m             kwargs = dict((k, _instantiate(v, bindings))\n\u001b[1;32m--> 229\u001b[1;33m                           for k, v in proxy.keywords.iteritems())\n\u001b[0m\u001b[0;32m    230\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchecked_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/perellm1/git/pylearn2/pylearn2/config/yaml_parse.py\u001b[0m in \u001b[0;36m_instantiate\u001b[1;34m(proxy, bindings)\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[1;31m# Is the key instantiation feature ever actually used, by anyone?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         return dict((_instantiate(k, bindings), _instantiate(v, bindings))\n\u001b[1;32m--> 285\u001b[1;33m                     for k, v in proxy.iteritems())\n\u001b[0m\u001b[0;32m    286\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_instantiate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbindings\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mproxy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/perellm1/git/pylearn2/pylearn2/config/yaml_parse.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m((k, v))\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[1;31m# Is the key instantiation feature ever actually used, by anyone?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         return dict((_instantiate(k, bindings), _instantiate(v, bindings))\n\u001b[1;32m--> 285\u001b[1;33m                     for k, v in proxy.iteritems())\n\u001b[0m\u001b[0;32m    286\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_instantiate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbindings\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mproxy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/perellm1/git/pylearn2/pylearn2/config/yaml_parse.py\u001b[0m in \u001b[0;36m_instantiate\u001b[1;34m(proxy, bindings)\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[0mbindings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mProxy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_instantiate_proxy_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbindings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[1;31m# Recurse on the keys too, for backward compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/perellm1/git/pylearn2/pylearn2/config/yaml_parse.py\u001b[0m in \u001b[0;36m_instantiate_proxy_tuple\u001b[1;34m(proxy, bindings)\u001b[0m\n\u001b[0;32m    228\u001b[0m             kwargs = dict((k, _instantiate(v, bindings))\n\u001b[0;32m    229\u001b[0m                           for k, v in proxy.keywords.iteritems())\n\u001b[1;32m--> 230\u001b[1;33m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchecked_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myaml_src\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproxy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myaml_src\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/perellm1/git/pylearn2/pylearn2/utils/call_check.py\u001b[0m in \u001b[0;36mchecked_call\u001b[1;34m(to_call, kwargs)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \"\"\"\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mto_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mcheck_call_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_call\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/perellm1/git/pylearn2/pylearn2/datasets/mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, which_set, center, shuffle, one_hot, binarize, start, stop, axes, preprocessor, fit_preprocessor, fit_test_preprocessor)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;31m# mnist_ubyte.py as stand-alone as possible (for reuse in, e.g.,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;31m# the Deep Learning Tutorials, or in another package).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[0mim_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mserial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[0mlabel_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mserial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/perellm1/git/pylearn2/pylearn2/utils/string_utils.py\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(string, environ)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvarname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'PYLEARN2_DATA_PATH'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m                 \u001b[0mreraise_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNoDataPathError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvarname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'PYLEARN2_VIEWER_COMMAND'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m                 reraise_as(EnvironmentVariableError(\n",
        "\u001b[1;32m/home/perellm1/git/pylearn2/pylearn2/utils/string_utils.py\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(string, environ)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             val = (environ[varname] if varname in environ\n\u001b[1;32m---> 50\u001b[1;33m                    else os.environ[varname])\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvarname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'PYLEARN2_DATA_PATH'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/share/imagedb/perellm1/anaconda/lib/python2.7/UserDict.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"__missing__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__missing__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__delitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNoDataPathError\u001b[0m: You need to define your PYLEARN2_DATA_PATH environment variable. If you are\nusing a computer at LISA, this should be set to /data/lisa/data.\n\nPlatform-specific instructions for setting environment variables:\n\nLinux\n=====\nOn most linux setups, you can define your environment variable by adding this\nline to your ~/.bashrc file:\n\nexport PYLEARN2_VIEWER_COMMAND=\"eog --new-instance\"\n\n*** YOU MUST INCLUDE THE WORD \"export\". DO NOT JUST ASSIGN TO THE ENVIRONMENT VARIABLE ***\nIf you do not include the word \"export\", the environment variable will be set\nin your bash shell, but will not be visible to processes that you launch from\nit, like the python interpreter.\n\nDon't forget that changes from your .bashrc file won't apply until you run\n\nsource ~/.bashrc\n\nor open a new terminal window. If you're seeing this from an ipython notebook\nyou'll need to restart the ipython notebook, or maybe modify os.environ from\nan ipython cell.\n\nMac OS X\n========\n\nEnvironment variables on Mac OS X work the same as in Linux, except you should\nmodify and run the \"source\" command on ~/.profile rather than ~/.bashrc.\n\n\nOriginal exception:\n\tKeyError: PYLEARN2_DATA_PATH"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Compiling the theano functions used to run the network will take a long time for this example. This is because the number of theano variables and ops used to specify the computation is relatively large. There is no single theano op for doing max pooling with overlapping pooling windows, so pylearn2 builds a large expression graph using indexing operations to accomplish the max pooling."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After the model is trained, we can use the print_monitor script to print the last monitoring entry of a saved model. By running it on \"convolutional_network_best.pkl\", we can see the performance of the model at the point where it did the best on the validation set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!print_monitor.py convolutional_network_best.pkl | grep test_y_misclass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The test set error has dropped to 0.74%! This is a big improvement over the standard MLP.\n",
      "\n",
      "We can also look at the convolution kernels learned by the first layer, to see that the network is looking for shifted versions of small pieces of penstrokes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!show_weights.py convolutional_network_best.pkl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Further reading\n",
      "\n",
      "You can find more information on convolutional networks from the following sources:\n",
      "\n",
      "[LISA lab's Deep Learning Tutorials: Convolutional Neural Networks (LeNet)](http://deeplearning.net/tutorial/lenet.html)\n",
      "\n",
      "\n",
      "This is by no means a complete list."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}